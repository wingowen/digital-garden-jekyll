# 原理介绍

注意力机制的核心是计算一个**注意力权重分布**，然后根据这个分布对输入进行加权求和。

Seq2Seq with Attention。
![](assets/images/注意力机制-1.png)

