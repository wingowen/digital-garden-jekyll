
```
case 
when [condition] then [result] else [result] end

case 
when [condition] then [result]
when [condition] then [result]
else [result] 
end


时间处理
--法一：like运算符
select
    day(date) as day,
    count(question_id) as question_cnt
from question_practice_detail
where date like '2021-08%'
group by day(date);

--法二：regexp运算符
select
    day(date) as day,
    count(question_id) as question_cnt
from question_practice_detail
where date regexp '2021-08'
group by day(date);

--法三：substring提取日期
select
    day(date) as day,
    count(question_id) as question_cnt
from question_practice_detail
where substring(date,1,7) = '2021-08'
group by day(date);


```

- 熟悉 SQL 语言，熟悉数据库的开发和应用；
- 熟悉 ETL 数据处理的理论和操作，掌握主流 ETL 工具的实际使用经验，熟悉数据采集、清洗融合、指标维度梳理等技术操作；
- 熟悉数据仓库理论和技能，对数据建模、数据治理、数据标准、数据应用等有深入理解
- 掌握 Java、Python 等开发；有相关技术 Hive / Spark / lmpala 的实际项目经验，熟悉 Kafka / Flink / Redis / Rocket MQ 的使用，有实际项目使用经验；
- 工作踏实，自我驱动，工作主动性和协调能力强，至少熟悉一款 BI 分析工具。

为了满足这些数据相关岗位的任职要求，你需要构建一个涵盖 **数据库开发、ETL、数据仓库、编程开发、大数据工具链和BI分析** 的复合型知识体系。以下是分阶段的学习路径和实践建议：

---

### **一、基础核心技能（优先级最高）**
#### **1. SQL与数据库**
- **学习目标**：熟练编写复杂查询、优化性能、理解数据库内部机制。
- **学习路径**：
  - **SQL语法**：窗口函数、CTE、子查询、索引优化、执行计划分析。
  - **数据库实践**：
    - **MySQL**：安装配置、主从复制、InnoDB引擎特性。
    - **PostgreSQL**：JSONB类型、窗口函数、扩展插件（如PostGIS）。
    - **Oracle**：PL/SQL编程、分区表、AWR报告分析。
  - **实战建议**：
    - 刷题平台：LeetCode（数据库题）、HackerRank。
    - 场景模拟：设计电商订单系统的表结构，优化慢查询。

#### **2. ETL开发**
- **学习目标**：掌握数据抽取、清洗、转换的完整流程，熟练使用至少1-2种ETL工具。
- **学习路径**：
  - **理论**：数据清洗规则（去重、缺失值处理）、增量同步策略（CDC）、调度任务设计。
  - **工具实战**：
    - **Kettle（Pentaho）**：通过GUI设计作业流，学习组件（输入/输出/转换）。
    - **Informatica**：理解Mapping、Workflow、Session的配置（社区版或试用版）。
  - **实战建议**：
    - 项目案例：从MySQL抽取数据到Hive，清洗后生成聚合表。
    - 开源替代：Apache NiFi（可视化ETL工具）。

---

### **二、进阶技能（优先级次高）**
#### **3. 数据仓库与建模**
- **学习目标**：掌握维度建模、分层设计（ODS/DWD/DWS/ADS）、数据治理。
- **学习路径**：
  - **理论**：
    - **维度建模**：星型模型、雪花模型、缓慢变化维（SCD）。
    - **数据治理**：元数据管理、数据血缘、质量监控（如Great Expectations）。
  - **实战建议**：
    - 工具：使用Erwin或PowerDesigner设计数据模型。
    - 项目案例：搭建一个零售行业数仓，设计商品、订单、用户主题域。

#### **4. 编程与大数据技术**
- **学习目标**：能用Python/Java处理数据，熟悉大数据生态组件。
- **学习路径**：
  - **Python**：
    - 数据处理库：Pandas、PySpark。
    - 自动化脚本：连接数据库（`sqlalchemy`）、调用API（`requests`）。
  - **大数据栈**：
    - **Hive/Spark**：编写HQL、理解Spark RDD/DataFrame优化。
    - **Kafka/Flink**：搭建流处理管道（如实时统计用户点击量）。
  - **实战建议**：
    - 项目案例：用Spark分析日志数据，用Flink实现实时告警。
    - 环境搭建：使用Docker部署Hadoop集群（Cloudera QuickStart）。

---

### **三、工具链与软技能（优先级中）**
#### **5. BI工具**
- **学习目标**：能通过BI工具生成可视化报表，支持业务决策。
- **推荐工具**：
  - **Tableau**：仪表盘设计、计算字段、参数控制。
  - **Power BI**：DAX公式、数据建模、发布到云端。
- **实战建议**：
  - 案例：将数仓中的销售数据接入BI工具，制作月度销售趋势看板。

#### **6. 软技能与项目管理**
- **核心能力**：
  - **文档能力**：撰写技术方案（如ETL设计文档、数仓规范）。
  - **协调沟通**：参与需求评审会，理解业务方的指标口径。
  - **自我驱动**：通过GitHub或博客输出技术总结（如《Flink Exactly-Once实现原理》）。

---

### **四、学习资源与时间规划**
#### **学习资源推荐**
| **领域**       | **资源**                                                                 |
|----------------|-------------------------------------------------------------------------|
| **SQL/数据库**  | 《SQL必知必会》、Oracle官方文档、Percona博客                              |
| **ETL**        | 《Pentaho Kettle解决方案》、Informatica官方教程                          |
| **数据仓库**    | 《数据仓库工具箱（Kimball）》、阿里云DataWorks实践案例                     |
| **大数据**      | 《Spark权威指南》、Flink官方文档、Kafka the Definitive Guide             |
| **BI工具**      | Tableau Public社区、Power BI官方学习路径                                 |

#### **时间规划（3-6个月）**
- **第1-2个月**：SQL与数据库核心技能 + 完成1个ETL项目（如Kettle迁移数据）。
- **第3-4个月**：数据仓库建模 + Python/Spark实战（如用户行为分析）。
- **第5-6个月**：大数据组件集成（Kafka+Flink） + BI工具输出报告。

---

### **五、项目经验与简历优化**
#### **必须包含的项目类型**
1. **ETL管道**：  
   - 描述：从MySQL导出用户数据，清洗后加载到Hive，用Airflow调度任务。  
   - 技术栈：Kettle + Hive + Airflow。  
2. **实时数仓**：  
   - 描述：通过Kafka采集日志，用Flink计算实时UV/PV，结果存入Redis。  
   - 技术栈：Kafka + Flink + Redis。  
3. **BI分析**：  
   - 描述：基于数仓数据，用Tableau制作销售漏斗分析和用户留存看板。  

#### **简历撰写技巧**
- **量化成果**：如“优化ETL任务，将运行时间从2小时缩短至15分钟”。
- **技术关键词**：明确列出工具名称（如Kettle、Spark、Flink）。
- **开源贡献**：参与ETL工具插件开发或提交Bug修复（GitHub展示）。

---

### **六、面试准备**
- **高频问题**：
  - SQL：如何优化一个慢查询？窗口函数和GROUP BY的区别？
  - ETL：如何处理增量数据？Kettle的Transformation和Job的区别？
  - 数据仓库：维度建模和范式建模的适用场景？如何设计缓慢变化维？
  - 大数据：Spark Shuffle原理？Kafka如何保证消息不丢失？
- **模拟实战**：在牛客网、LeetCode参加模拟面试，录制技术分享视频（如B站）。

---

通过以上体系化学习，你可以逐步覆盖岗位要求的所有技术点。**关键是要以项目驱动学习**，避免陷入“只看不练”的陷阱。例如，可以自建一个个人数据平台（如采集GitHub数据进行分析），完整覆盖ETL→数仓→BI全流程，这将极大提升竞争力。