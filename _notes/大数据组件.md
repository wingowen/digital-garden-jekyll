[[Hadoop]]
- [[HDFS]] 存储引擎，高吞吐的离线大数据分析场景，不支持随机读写。
- [[Spark]] 计算引擎。

[[HBase]] 是一个分布式的、面向列的开源存储引擎，支持随机读写，吞吐量小，不适用于批量数据处理场景。

> 数据实时写入 HBase，实时的数据更新也在 HBase完成，为了应对 OLAP 需求，定时（通常是 T+1 或者 T+H）将 HBase 数据写成静态的文件导入到 OLAP 引擎（例如 Parquet => HDFS）。

>从根本上， HDFS 基于 03 年 GFS， HBase 基于 05 年 BigTable，在当时系统瓶颈主要取决于底层磁盘速度。 当磁盘速度较慢时， CPU 利用率不足的根本原因是磁盘速度导致的瓶颈，当磁盘速度提高了之后， CPU 利用率提高，这时候 CPU 往往成为系统的瓶颈。 HBase、 HDFS 由于年代久远，已经很难从基本架构上进行修改，而 Kudu是基于全新的设计，因此可以更充分地利用RAM、I/O 资源，并优化 CPU 利用率。

[[Kudu]] 支持随机读写的、OLAP 分析的大数据存储引擎。

[[Hive]] 查询引擎，将 HDFS 的数据映射为类 SQL 结构的数据，方便用户使用 SQL 语言进行操作。本质上是通过 MR 对数据进行处理。

[[Impala]] 查询引擎 SQL Syntax、计算引擎 Compute Framework，依赖于 Hive 元数据。

> 在一个 Hadoop 平台上，可以统一部署 Hive 和 Impala，同时支持批处理和实时查询。使用 Hive 进行数据转换处理，之后再使用 Impala 在 Hive 处理后的结果数据集上进行快速的数据分析。

> ODBC（Open Database Connectivity）是一种标准的数据库访问接口。

Yarn 资源管理

Sqoop

Kafka

Kettle

Zookeeper

